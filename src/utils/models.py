from langchain_deepseek import ChatDeepSeek
from langchain_core.output_parsers import StrOutputParser

def deep_seek_v3_stream(message):
    """
    ä½¿ç”¨ V3 æ¨¡å‹è¿›è¡Œæµå¼å¯¹è¯
    """
    # å®ä¾‹åŒ– V3 æ¨¡å‹
    # model="deepseek-chat" æŒ‡å‘çš„å°±æ˜¯æœ€æ–°çš„ V3
    llm = ChatDeepSeek(
        model="deepseek-chat",
        temperature=0.7,  # 0.7 é€‚åˆåˆ›æ„å’Œæ—¥å¸¸å¯¹è¯
        streaming=True,  # å¼€å¯æµå¼æ”¯æŒ
        max_retries=2,  # å¤±è´¥è‡ªåŠ¨é‡è¯•
    )

    # å¼€å§‹æµå¼è¾“å‡º
    for chunk in llm.stream(message):
        print(chunk.content, end="", flush=True)

def deep_seek_pro_stream(message):
    """
    ä¸“é—¨é’ˆå¯¹ä»˜è´¹æ¨¡å‹ (deepseek-reasoner/R1) çš„æµå¼è¾“å‡ºå‡½æ•°
    """
    # åˆå§‹åŒ–ä»˜è´¹æ¨¡å‹
    # model="deepseek-reasoner" å¯¹åº”æœ€æ–°çš„ R1 æ¨¡å‹
    llm = ChatDeepSeek(
        model="deepseek-reasoner",
        max_retries=3
    )

    print("ğŸš€ [ä»˜è´¹ç‰ˆ R1] æ­£åœ¨æ·±åº¦æ€è€ƒä¸­...\n")

    # åœ¨ R1 ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åŒºåˆ†â€œæ¨ç†â€å’Œâ€œæœ€ç»ˆç­”æ¡ˆâ€
    # æ³¨æ„ï¼šå¹¶éæ‰€æœ‰ç‰ˆæœ¬çš„ LangChain éƒ½èƒ½ç›´æ¥è§£ææ¨ç†å­—æ®µ
    # å¦‚æœæ˜¯æ ‡å‡†çš„ ChatDeepSeek åº“ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·æ•è·ï¼š

    for chunk in llm.stream(message):
        # 1. å°è¯•æ•è·æ¨ç†å†…å®¹ (Reasoning Content)
        # DeepSeek ä¸“ç”¨åº“é€šå¸¸å°†æ¨ç†å†…å®¹æ”¾åœ¨ additional_kwargs ä¸­
        if hasattr(chunk, 'additional_kwargs') and 'reasoning_content' in chunk.additional_kwargs:
            # ç°åº¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ï¼ˆæ¨¡æ‹Ÿæ€è€ƒæ„Ÿï¼‰
            reasoning = chunk.additional_kwargs['reasoning_content']
            print(f"\033[90m{reasoning}\033[0m", end="", flush=True)

        # 2. æ­£å¸¸æ‰“å°æœ€ç»ˆç­”æ¡ˆå†…å®¹
        if chunk.content:
            print(chunk.content, end="", flush=True)

# src/models.py

def deep_seek_v3_chain():
    """
    åˆ›å»ºä¸€ä¸ªä¸“ç”¨çš„ V3 é“¾æ¡å®ä¾‹
    """
    llm = ChatDeepSeek(model="deepseek-chat", temperature=0.7)
    # è¿”å›ä¸€ä¸ªæœªå¡«å……æ•°æ®çš„é“¾æ¡
    # åŠ ä¸Š StrOutputParser() å¯ä»¥ç›´æ¥æŠŠç»“æœè½¬ä¸ºå­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿æµå¼è¾“å‡º
    return llm | StrOutputParser()